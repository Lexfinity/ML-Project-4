{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNforSentimentAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_LYE2HYIPAC",
        "colab_type": "text"
      },
      "source": [
        "Various imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzAWNkM4IJhn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "650ab9c6-4a0a-439c-f81c-b7532f549145"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.layers import Dense, Input, Flatten, Reshape, concatenate, Dropout\n",
        "from keras.layers import Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Embedding\n",
        "from keras.layers import LSTM, Bidirectional\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras import regularizers\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from keras.datasets import imdb\n",
        "from gensim.models import word2vec"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2-Y35FNFgU0",
        "colab_type": "text"
      },
      "source": [
        "Read in Movie Review Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED21R2KxFfpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 32\n",
        "num_words = 88585\n",
        "embed = 32\n",
        "filter_size = 32\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words,seed=42)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "vocabulary = imdb.get_word_index()\n",
        "vocabulary_inv = dict((v, k) for k, v in vocabulary.items())\n",
        "vocabulary_inv[0] = \"<PAD/>\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN2hWX88IWP4",
        "colab_type": "text"
      },
      "source": [
        "Create the CNN-rand model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRdkH2tnG5Z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_input = Input(shape=(maxlen,), dtype='int32')\n",
        "\n",
        "e = Embedding(num_words, embed, input_length=maxlen)(sequence_input)\n",
        "\n",
        "e = Reshape((maxlen, embed, 1))(e)\n",
        "\n",
        "x = Conv2D(filter_size, (5, embed), activation='relu')(e)\n",
        "x = MaxPooling2D((3, 1))(x)\n",
        "x = Flatten()(x)\n",
        "\n",
        "y = Conv2D(filter_size, (4, embed), activation='relu')(e)\n",
        "y = MaxPooling2D((3, 1))(y)\n",
        "y = Flatten()(y)\n",
        "\n",
        "z = Conv2D(filter_size, (3, embed), activation='relu')(e)\n",
        "z = MaxPooling2D((3, 1))(z)\n",
        "z = Flatten()(z)\n",
        "\n",
        "alpha = concatenate([x,y,z])\n",
        "\n",
        "alpha = Dropout(0.5)(alpha)\n",
        "\n",
        "layer_a = Dense(128, activation='relu')(alpha)\n",
        "\n",
        "layer_b = Dense(64, activation='relu')(layer_a)\n",
        "\n",
        "layer_c = Dense(32, activation='relu')(layer_b)\n",
        "\n",
        "preds = Dense(1, activation='sigmoid')(layer_c)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "    \n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs9TD-xWIrRX",
        "colab_type": "text"
      },
      "source": [
        "Train the model and print accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkH8PgXnIokG",
        "colab_type": "code",
        "outputId": "81be982f-8431-4203-bcac-1eadfcb60493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=256,\n",
        "          epochs=5,\n",
        "          validation_data=(x_test, y_test))\n",
        "print(\" \")\n",
        "print(\"---Results---\")\n",
        "print(\" \")\n",
        "print(\"Training accuracy:\")\n",
        "print(model.evaluate(x_train, y_train)[1])\n",
        "print(\" \")\n",
        "print(\"Testing accuracy:\")\n",
        "print(model.evaluate(x_test, y_test)[1])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/5\n",
            "25000/25000 [==============================] - 65s 3ms/step - loss: 0.4065 - acc: 0.7975 - val_loss: 0.2829 - val_acc: 0.8814\n",
            "Epoch 2/5\n",
            "25000/25000 [==============================] - 59s 2ms/step - loss: 0.1300 - acc: 0.9526 - val_loss: 0.3181 - val_acc: 0.8746\n",
            "Epoch 3/5\n",
            "25000/25000 [==============================] - 59s 2ms/step - loss: 0.0368 - acc: 0.9889 - val_loss: 0.4681 - val_acc: 0.8643\n",
            "Epoch 4/5\n",
            "25000/25000 [==============================] - 59s 2ms/step - loss: 0.0110 - acc: 0.9969 - val_loss: 0.9060 - val_acc: 0.8413\n",
            "Epoch 5/5\n",
            "25000/25000 [==============================] - 59s 2ms/step - loss: 0.0049 - acc: 0.9981 - val_loss: 0.8148 - val_acc: 0.8652\n",
            " \n",
            "---Results---\n",
            " \n",
            "Training accuracy:\n",
            "25000/25000 [==============================] - 18s 731us/step\n",
            "0.99928\n",
            " \n",
            "Testing accuracy:\n",
            "25000/25000 [==============================] - 18s 726us/step\n",
            "0.86524\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYRhEb0BpMgg",
        "colab_type": "text"
      },
      "source": [
        "For CNN-non-static and CNN-static embedding weights must be calculated using the word2vec module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01d4DHfYJO9p",
        "colab_type": "code",
        "outputId": "4fa3639e-1e02-41c4-8148-75e51838c774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "sentences = [[vocabulary_inv[w] for w in s] for s in np.vstack((x_train, x_test))]\n",
        "embedding_model = word2vec.Word2Vec(sentences,\n",
        "                                    size=embed, \n",
        "                                    min_count=1,\n",
        "                                    window=10, \n",
        "                                    sample=1e-3)\n",
        "embedding_weights = {key: embedding_model[word] if word in embedding_model else\n",
        "                              np.random.uniform(-0.25, 0.25, embedding_model.vector_size)\n",
        "                         for key, word in vocabulary_inv.items()}"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnAoxiYdqRuD",
        "colab_type": "text"
      },
      "source": [
        "For the CNN-non-static the only modification that has to be made is adding the embedding weights to the Embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajgT7OOTpeOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_input = Input(shape=(maxlen,), dtype='int32')\n",
        "\n",
        "e = Embedding(num_words, embed, input_length=maxlen, name=\"embedding\")(sequence_input)\n",
        "\n",
        "e = Reshape((maxlen, embed, 1))(e)\n",
        "\n",
        "x = Conv2D(filter_size, (5, embed), activation='relu')(e)\n",
        "x = MaxPooling2D((3, 1))(x)\n",
        "x = Flatten()(x)\n",
        "\n",
        "y = Conv2D(filter_size, (4, embed), activation='relu')(e)\n",
        "y = MaxPooling2D((3, 1))(y)\n",
        "y = Flatten()(y)\n",
        "\n",
        "z = Conv2D(filter_size, (3, embed), activation='relu')(e)\n",
        "z = MaxPooling2D((3, 1))(z)\n",
        "z = Flatten()(z)\n",
        "\n",
        "alpha = concatenate([x,y,z])\n",
        "\n",
        "alpha = Dropout(0.5)(alpha)\n",
        "\n",
        "layer_a = Dense(128, activation='relu')(alpha)\n",
        "\n",
        "layer_b = Dense(64, activation='relu')(layer_a)\n",
        "\n",
        "layer_c = Dense(32, activation='relu')(layer_b)\n",
        "\n",
        "preds = Dense(1, activation='sigmoid')(layer_c)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "    \n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVWfhJvXq66C",
        "colab_type": "text"
      },
      "source": [
        "Add the weights to the embeddnig layer, train the model and print accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arSab8O9q8XR",
        "colab_type": "code",
        "outputId": "39fb67f5-3d61-4e61-d0b9-89cf119df4a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "weights = np.array([v for v in embedding_weights.values()])\n",
        "embedding_layer = model.get_layer(\"embedding\")\n",
        "embedding_layer.set_weights([weights])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=256,\n",
        "          epochs=5,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "print(\" \")\n",
        "print(\"---Results---\")\n",
        "print(\" \")\n",
        "print(\"Training accuracy:\")\n",
        "print(model.evaluate(x_train, y_train)[1])\n",
        "print(\" \")\n",
        "print(\"Testing accuracy:\")\n",
        "print(model.evaluate(x_test, y_test)[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/5\n",
            "25000/25000 [==============================] - 11s 451us/step - loss: 0.6260 - acc: 0.6235 - val_loss: 0.4238 - val_acc: 0.8067\n",
            "Epoch 2/5\n",
            "25000/25000 [==============================] - 10s 393us/step - loss: 0.3025 - acc: 0.8739 - val_loss: 0.3322 - val_acc: 0.8561\n",
            "Epoch 3/5\n",
            "25000/25000 [==============================] - 10s 393us/step - loss: 0.1373 - acc: 0.9496 - val_loss: 0.3841 - val_acc: 0.8509\n",
            "Epoch 4/5\n",
            "25000/25000 [==============================] - 10s 393us/step - loss: 0.0491 - acc: 0.9848 - val_loss: 0.5084 - val_acc: 0.8420\n",
            "Epoch 5/5\n",
            "25000/25000 [==============================] - 10s 393us/step - loss: 0.0179 - acc: 0.9949 - val_loss: 0.7183 - val_acc: 0.8380\n",
            " \n",
            "---Results---\n",
            " \n",
            "Training accuracy:\n",
            "25000/25000 [==============================] - 4s 154us/step\n",
            "0.99804\n",
            " \n",
            "Testing accuracy:\n",
            "25000/25000 [==============================] - 4s 152us/step\n",
            "0.83796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GDB1TC2ulVY",
        "colab_type": "text"
      },
      "source": [
        "For the CNN-static we must first modify the x_train and y_test vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPYBG7zIrqoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.stack([np.stack([embedding_weights[word] for word in sentence]) for sentence in x_train])\n",
        "x_test = np.stack([np.stack([embedding_weights[word] for word in sentence]) for sentence in x_test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20N05x1kuuoy",
        "colab_type": "text"
      },
      "source": [
        "And modify the model to accept the new input shape. In edition we have no need for the embedding layer since the embeddings are already found"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "826W89CRusrK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "dcf17b40-50c8-436c-dc09-d250d59748d2"
      },
      "source": [
        "sequence_input = Input(shape=(maxlen,embed), dtype='float32')\n",
        "\n",
        "e = Reshape((maxlen, embed, 1))(sequence_input)\n",
        "\n",
        "x = Conv2D(filter_size, (5, embed), activation='relu')(e)\n",
        "x = MaxPooling2D((3, 1))(x)\n",
        "x = Flatten()(x)\n",
        "\n",
        "y = Conv2D(filter_size, (4, embed), activation='relu')(e)\n",
        "y = MaxPooling2D((3, 1))(y)\n",
        "y = Flatten()(y)\n",
        "\n",
        "z = Conv2D(filter_size, (3, embed), activation='relu')(e)\n",
        "z = MaxPooling2D((3, 1))(z)\n",
        "z = Flatten()(z)\n",
        "\n",
        "alpha = concatenate([x,y,z])\n",
        "\n",
        "alpha = Dropout(0.5)(alpha)\n",
        "\n",
        "layer_a = Dense(128, activation='relu')(alpha)\n",
        "\n",
        "layer_b = Dense(64, activation='relu')(layer_a)\n",
        "\n",
        "layer_c = Dense(32, activation='relu')(layer_b)\n",
        "\n",
        "preds = Dense(1, activation='sigmoid')(layer_c)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "    \n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOkt1z6LvGbs",
        "colab_type": "text"
      },
      "source": [
        "Train and print accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb3ATSSbvCOj",
        "colab_type": "code",
        "outputId": "4ee280a4-6193-4388-867c-14113c7fffd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=256,\n",
        "          epochs=5,\n",
        "          validation_data=(x_test, y_test))\n",
        "print(\" \")\n",
        "print(\"---Results---\")\n",
        "print(\" \")\n",
        "print(\"Training accuracy:\")\n",
        "print(model.evaluate(x_train, y_train)[1])\n",
        "print(\" \")\n",
        "print(\"Testing accuracy:\")\n",
        "print(model.evaluate(x_test, y_test)[1])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/5\n",
            "25000/25000 [==============================] - 2s 64us/step - loss: 0.6238 - acc: 0.6337 - val_loss: 0.5462 - val_acc: 0.7176\n",
            "Epoch 2/5\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.5388 - acc: 0.7238 - val_loss: 0.5199 - val_acc: 0.7321\n",
            "Epoch 3/5\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.5151 - acc: 0.7389 - val_loss: 0.5206 - val_acc: 0.7322\n",
            "Epoch 4/5\n",
            "25000/25000 [==============================] - 1s 31us/step - loss: 0.5029 - acc: 0.7481 - val_loss: 0.5121 - val_acc: 0.7377\n",
            "Epoch 5/5\n",
            "25000/25000 [==============================] - 1s 31us/step - loss: 0.4870 - acc: 0.7571 - val_loss: 0.4929 - val_acc: 0.7506\n",
            " \n",
            "---Results---\n",
            " \n",
            "Training accuracy:\n",
            "25000/25000 [==============================] - 1s 57us/step\n",
            "0.79104\n",
            " \n",
            "Testing accuracy:\n",
            "25000/25000 [==============================] - 1s 56us/step\n",
            "0.75056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq5fojItvJ5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}